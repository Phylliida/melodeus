# Voice AI System Configuration
# Copy this file to config.yaml and fill in your API keys

# API Keys
api_keys:
  deepgram: "your_deepgram_api_key_here"
  elevenlabs: "your_elevenlabs_api_key_here" 
  openai: "your_openai_api_key_here"

# Voice Settings
voice:
  id: "T2KZm9rWPG5TgXTyjt7E"  # Catalyst voice (default)
  # Other popular voices:
  # "pNInz6obpgDQGcFmaJgB"  # Rachel
  # "yjJ45q8TVCrtMhEKurxY"  # Von Fusion
  # "EXAVITQu4vr4xnSDxMaL"  # Sarah
  # "21m00Tcm4TlvDq8ikWAM"  # Rachel (alternative)

# Speech-to-Text Settings  
stt:
  model: "nova-3"
  language: "en-US"
  sample_rate: 16000
  chunk_size: 8000
  interim_results: true
  punctuate: true
  diarize: true
  utterance_end_ms: 1000
  vad_events: true
  enable_speaker_id: true
  speaker_profiles_path: "speaker_profiles"
  debug_speaker_data: true  # Show detailed word-level timing and speaker info

# Speaker Configuration
speakers:
  # Configure known speakers you want the system to recognize
  # Provide 30+ second reference audio samples for each person
  profiles:
    "user_primary":
      name: "Alice"
      description: "Primary user"
      reference_audio: "speaker_profiles/alice_reference.wav"  # 30+ seconds of clean speech
    "user_secondary": 
      name: "Bob"
      description: "Secondary user or colleague"
      reference_audio: "speaker_profiles/bob_reference.wav"    # 30+ seconds of clean speech
    "user_guest":
      name: "Guest"
      description: "Occasional participant"
      reference_audio: null  # No reference - will be learned automatically
  
  # Speaker recognition settings
  recognition:
    confidence_threshold: 0.7  # Minimum confidence for speaker identification
    learning_mode: true        # Whether to learn new speakers automatically
    max_speakers: 4           # Maximum number of speakers to track
    voice_fingerprint_length: 128  # Size of voice fingerprint vector

# Text-to-Speech Settings
tts:
  model_id: "eleven_multilingual_v2"
  output_format: "pcm_22050"
  sample_rate: 22050
  speed: 1.0
  stability: 0.5
  similarity_boost: 0.8
  chunk_size: 1024
  buffer_size: 2048

# Conversation Management
conversation:
  # Timing settings
  pause_threshold: 2.0        # seconds of silence before LLM submission
  min_words_for_submission: 3 # minimum words before submitting
  max_wait_time: 10.0         # maximum time to wait before force submission
  
  # Interruption settings
  interruptions_enabled: false  # whether voice interruptions are allowed (default: false)
  interruption_confidence: 0.8 # minimum confidence for interruption
  
  # Director settings
  director_enabled: false       # whether director is enabled to select speakers (default: false)
  
  # Echo cancellation settings
  enable_echo_cancellation: false  # enable acoustic echo cancellation (requires speexdsp)
  aec_frame_size: 256             # frame size for echo cancellation (must be power of 2)
  aec_filter_length: 2048         # length of the echo cancellation filter
  aec_delay_ms: 100               # reference delay in milliseconds to compensate for audio latency
  
  # LLM settings
  llm_model: "chatgpt-4o-latest"
  max_tokens: 300
  system_prompt: "You are a helpful AI assistant in a voice conversation. Give natural, conversational responses that work well when spoken aloud. Keep responses concise but engaging."

# Audio Device Settings (optional)
audio:
  input_device_name: null   # null for default microphone, or specify device name like "Scarlett 18i20"
  output_device_name: null  # null for default speakers, or specify device name like "Loopback Audio"
  stream_sample_rate: 48000  # Shared mel-aec duplex stream sample rate (Hz)
  stream_channels: 1         # Number of channels for shared stream
  stream_buffer_size: 480    # Buffer size in samples (approx 10 ms at 48 kHz)
  stream_enable_aec: null    # true/false to force enable/disable AEC, null to inherit conversation.enable_echo_cancellation
  aec_filter_length: 2048    # Override AEC filter length (samples) if needed

# Logging Settings
logging:
  level: "INFO"              # DEBUG, INFO, WARNING, ERROR
  show_interim_results: true
  show_tts_chunks: false
  show_audio_debug: false

# Development/Testing Settings
development:
  enable_debug_mode: false
  test_mode: false
  mock_apis: false 
